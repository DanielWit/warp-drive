# Copyright (c) 2021, salesforce.com, inc.
# All rights reserved.
# SPDX-License-Identifier: BSD-3-Clause
# For full license text, see the LICENSE file in the repo root
# or https://opensource.org/licenses/BSD-3-Clause
#
# YAML configuration for the tag continuous environment
name: "tag_continuous"
# Environment settings
env:
    num_taggers: 10
    num_runners: 100
    grid_length: 100.0
    episode_length: 500
    max_acceleration: 0.1
    min_acceleration: -0.1
    max_turn: 2.35 # 3*pi/4 radians
    min_turn: -2.35 # -3*pi/4 radians
    num_acceleration_levels: 20
    num_turn_levels: 20
    skill_level_runner: 1.0
    skill_level_tagger: 0.5
    max_speed: 1.0
    seed: 274880
    use_full_observation: False
    runner_exits_game_after_tagged: True
    num_other_agents_observed: 10
    tag_reward_for_tagger: 10.0
    tag_penalty_for_runner: -10.0
    step_penalty_for_tagger: -0.00
    step_reward_for_runner: 0.00
    edge_hit_penalty: -0.0
    end_of_game_reward_for_runner: 1.0
    tagging_distance: 0.02
# Trainer settings
trainer:
    num_envs: 5 # Number of environment replicas
    num_episodes: 1000000000 # Number of episodes to run the training for
    train_batch_size: 1250 # total batch size used for training per iteration (across all the environments)
    algorithm: "A2C" # trainer algorithm
    vf_loss_coeff: 1 # loss coefficient for the value function loss
    entropy_coeff: 0.05 # coefficient for the entropy component of the loss
    clip_grad_norm: True # fla indicating whether to clip the gradient norm or not
    max_grad_norm: 0.5 # when clip_grad_norm is True, the clip level
    normalize_advantage: False # flag indicating whether to normalize advantage or not
    normalize_return: False # flag indicating whether to normalize return or not
# Policy network settings
policy: # list all the policies below
    runner:
        to_train: True
        name: "fully_connected"
        gamma: 0.98 # discount rate gamms
        lr: 0.005 # learning rate
        model:
        # dimension(s) of the fully connected layers as a list
            fc_dims: [256, 256]
            model_ckpt_filepath: ""
    tagger:
        to_train: True
        name: "fully_connected"
        gamma: 0.98
        lr: 0.002
        model:
            fc_dims: [256, 256]
            model_ckpt_filepath: ""
# Checkpoint saving setting (and W&B logging)
saving:
    print_metrics_freq: 100 # How often (in iterations) to print the metrics
    save_model_params_freq: 5000 # How often (in iterations) to save the model parameters
    basedir: "/tmp" # base folder used for saving
    tag: "experiments"
