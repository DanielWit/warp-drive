{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ade13c1",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df0c7e8",
   "metadata": {},
   "source": [
    "This notebook provides a demonstration of an end-to-end RL training loop with [WarpDrive](https://github.com/salesforce/warp-drive). WarpDrive is a flexible, lightweight, and easy-to-use open-source RL framework that implements end-to-end deep multi-agent RL on a single GPU (Graphics Processing Unit). Using the extreme parallelization capability of GPUs, WarpDrive enables orders-of-magnitude faster RL compared to common implementations that blend CPU simulations and GPU models. We have built WarpDrive using PyCuda and the flexible [Pytorch Lightning](https://www.pytorchlightning.ai/) framework.\n",
    "\n",
    "Below, we demonstrate how to use WarpDrive to train a game of [Tag](https://github.com/salesforce/warp-drive/blob/master/example_envs/tag_continuous/tag_continuous.py) with mutiple tagger and runner agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f37d334",
   "metadata": {},
   "source": [
    "## This notebook requires the rl-warp-drive as well as the pytorch-lightning packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77cc5cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip install --quiet rl_warp_drive pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50124771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from example_envs.tag_continuous.tag_continuous import TagContinuous\n",
    "from warp_drive.env_wrapper import EnvWrapper\n",
    "from warp_drive.training.lightning_trainer import WarpDriveModel, PerfStatsCallback\n",
    "from warp_drive.training.utils.data_loader import create_and_push_data_placeholders\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8ad0a4",
   "metadata": {},
   "source": [
    "# Specify a set of run configurations for your experiments\n",
    "This includes settings for the environment, the trainer, the policy network, as well as configurations for saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001f43dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = dict(\n",
    "    name=\"tag_continuous\",\n",
    "    # Environment settings.\n",
    "    env=dict(\n",
    "        num_taggers=5,\n",
    "        num_runners=20,\n",
    "        episode_length=100,\n",
    "        seed=1234,\n",
    "        use_full_observation=False,\n",
    "        num_other_agents_observed=10,\n",
    "        tagging_distance=0.02,\n",
    "    ),\n",
    "    # Trainer settings.\n",
    "    trainer=dict(\n",
    "        num_envs=100,  # number of environment replicas (number of GPU blocks used)\n",
    "        train_batch_size=10000,  # total batch size used for training per iteration (across all the environments)\n",
    "        num_episodes=5000,  # total number of episodes to run the training for (can be arbitrarily high!)\n",
    "    ),\n",
    "    # Policy network settings.\n",
    "    policy=dict(\n",
    "        runner=dict(\n",
    "            to_train=False,  # flag indicating whether the model needs to be trained\n",
    "            algorithm=\"A2C\",  # algorithm used to train the policy\n",
    "            gamma=0.98,  # discount rate\n",
    "            lr=0.005,  # learning rate\n",
    "            model=dict(\n",
    "                type=\"fully_connected\", fc_dims=[256, 256], model_ckpt_filepath=\"\"\n",
    "            ),  # policy model settings\n",
    "        ),\n",
    "        tagger=dict(\n",
    "            to_train=True,\n",
    "            algorithm=\"A2C\",\n",
    "            gamma=0.98,\n",
    "            lr=0.002,\n",
    "            model=dict(\n",
    "                type=\"fully_connected\", fc_dims=[256, 256], model_ckpt_filepath=\"\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    # Checkpoint saving setting.\n",
    "    saving=dict(\n",
    "        metrics_log_freq=100,  # how often (in iterations) to print the metrics\n",
    "        model_params_save_freq=5000,  # how often (in iterations) to save the model parameters\n",
    "        basedir=\"/tmp\",  # base folder used for saving\n",
    "        name=\"continuous_tag\",  # experiment name\n",
    "        tag=\"example\",  # experiment tag\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681b1cdb",
   "metadata": {},
   "source": [
    "# Instantiate the WarpDrive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745d60ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logger level e.g., DEBUG, INFO, WARNING, ERROR.\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcf322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a wrapped environment object via the EnvWrapper.\n",
    "# Ensure that use_cuda is set to True (in order to run on the GPU).\n",
    "env_wrapper = EnvWrapper(\n",
    "    TagContinuous(**run_config[\"env\"]),\n",
    "    num_envs=run_config[\"trainer\"][\"num_envs\"],\n",
    "    use_cuda=True,\n",
    ")\n",
    "\n",
    "# Agents can share policy models: this dictionary maps policy model names to agent ids.\n",
    "policy_tag_to_agent_id_map = {\n",
    "    \"tagger\": list(env_wrapper.env.taggers),\n",
    "    \"runner\": list(env_wrapper.env.runners),\n",
    "}\n",
    "\n",
    "wd_model = WarpDriveModel(\n",
    "    env_wrapper=env_wrapper,\n",
    "    config=run_config,\n",
    "    policy_tag_to_agent_id_map=policy_tag_to_agent_id_map,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c9567c",
   "metadata": {},
   "source": [
    "# Create the Lightning Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a2df41",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_parser = argparse.ArgumentParser(add_help=False)\n",
    "parent_parser = Trainer.add_argparse_args(parent_parser)\n",
    "parser = WarpDriveModel.add_model_specific_args(parent_parser)\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "# Define callbacks.\n",
    "# 1. Save checkpoints based on avg_reward.\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    save_top_k=1, monitor=\"avg_reward\", mode=\"max\", verbose=True\n",
    ")\n",
    "# 2. Save performance stats.\n",
    "perf_stats_callback = PerfStatsCallback(\n",
    "    batch_size=wd_model.training_batch_size,\n",
    "    num_iters=wd_model.num_iters,\n",
    "    log_freq=run_config[\"saving\"][\"metrics_log_freq\"]\n",
    ")\n",
    "\n",
    "# Instantiate the PytorchLightning trainer.\n",
    "trainer = Trainer.from_argparse_args(\n",
    "    args, deterministic=True, callbacks=[checkpoint_callback, perf_stats_callback], gpus=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76c17b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch to fix cuda determinism.\n",
    "# Reference: https://discuss.pytorch.org/t/torch-deterministic-algorithms-error/125200/6\n",
    "# TODO: Find a fix for this!\n",
    "torch.use_deterministic_algorithms(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d09e27",
   "metadata": {},
   "source": [
    "# Train the WarpDrive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba66c41",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer.fit(wd_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fc20e5",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00ab6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start tensorboard.\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
